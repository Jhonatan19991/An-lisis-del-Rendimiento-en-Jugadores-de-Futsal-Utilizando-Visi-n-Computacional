{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcypZrYSx0lt",
        "outputId": "33b5e684-8e79-4f0f-b565-ccff67baa2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.110-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.110-py3-none-any.whl (978 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.8/978.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.110 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BcUM8vIWiYmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6PX7Kg49T4-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l8E1sR6rvwZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Detección de balón arco (resultado a color)**"
      ],
      "metadata": {
        "id": "8LK8QevMicaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código procesa un video, detectando objetos con YOLO mientras mantiene el video a color, aunque la detección se haga en escala de grises.\n",
        "\n",
        "**📌 En resumen:**\n",
        "\n",
        "\n",
        "*   Carga un video de entrada.\n",
        "*   Convierte cada fotograma a escala de grises para hacer la detección.\n",
        "*   Redimensiona la imagen a 640x640 (para ajustarse al modelo YOLO).\n",
        "*   Convierte la imagen de grises a BGR antes de pasarla a YOLO.\n",
        "*   Usa YOLO para detectar objetos y obtener coordenadas de las cajas.\n",
        "*   Dibuja las cajas sobre el fotograma original en color (para que el video de salida se mantenga en color).\n",
        "*   Guarda el video con las detecciones en color.\n"
      ],
      "metadata": {
        "id": "pzQmovoUlqmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade torch ultralytics"
      ],
      "metadata": {
        "id": "m0sCCFk8VzPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Intentamos configurar torch._dynamo para saltar los hooks de FSDP\n",
        "try:\n",
        "    import torch._dynamo\n",
        "    torch._dynamo.config.skip_fsdp_hooks = True\n",
        "except AttributeError:\n",
        "    print(\"No se pudo configurar torch._dynamo.config. Revisa la versión de PyTorch.\")\n",
        "\n",
        "class VideoProcessor:\n",
        "    def __init__(self, model_path):\n",
        "        # Carga del modelo personalizado\n",
        "        self.model = YOLO(model_path)\n",
        "        # Mapeo de clases: ajusta según corresponda a tu entrenamiento\n",
        "        self.class_names = {0: \"balon\", 1: \"arco\"}\n",
        "        # Mapeo de colores en formato BGR\n",
        "        self.colors = {\n",
        "            \"balón\": (0, 0, 255),      # rojo\n",
        "            \"arco\": (255, 0, 0)   # azul\n",
        "        }\n",
        "\n",
        "    def process_video(self, input_path, output_path):\n",
        "        # Abrimos el video de entrada\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise IOError(f\"No se pudo abrir el video: {input_path}\")\n",
        "\n",
        "        # Obtenemos las propiedades del video original\n",
        "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        # Procesamos cada fotograma del video\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Guardamos una copia del frame original a color\n",
        "            original_frame = frame.copy()\n",
        "\n",
        "            # Convertir a escala de grises para detección\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            resized = cv2.resize(gray, (640, 640))\n",
        "\n",
        "            # Convertimos de nuevo a 3 canales para YOLO (BGR)\n",
        "            input_frame = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            # Hacer la detección en la imagen en escala de grises con 3 canales\n",
        "            results = self.model(input_frame)\n",
        "\n",
        "            # Extraemos las cajas detectadas, sus coordenadas y clases\n",
        "            boxes = results[0].boxes\n",
        "            xyxy = boxes.xyxy.cpu().numpy()\n",
        "            confs = boxes.conf.cpu().numpy()\n",
        "            classes = boxes.cls.cpu().numpy()\n",
        "\n",
        "            # Calculamos el factor de escala para volver a mapear las coordenadas al tamaño original del video\n",
        "            scale_x = width / 640\n",
        "            scale_y = height / 640\n",
        "\n",
        "            # Dibujamos las cajas de detección en el fotograma original a color\n",
        "            for (x1, y1, x2, y2), conf, cls in zip(xyxy, confs, classes):\n",
        "                # Convertimos las coordenadas de vuelta al tamaño original\n",
        "                x1 = int(x1 * scale_x)\n",
        "                y1 = int(y1 * scale_y)\n",
        "                x2 = int(x2 * scale_x)\n",
        "                y2 = int(y2 * scale_y)\n",
        "\n",
        "                label = self.class_names.get(int(cls), str(cls))\n",
        "                color = self.colors.get(label, (0, 255, 0))\n",
        "                cv2.rectangle(original_frame, (x1, y1), (x2, y2), color, 2)\n",
        "                cv2.putText(original_frame, f\"{label} {conf:.2f}\", (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "            # Escribir el fotograma procesado con detecciones en el video de salida\n",
        "            out.write(original_frame)\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        return output_path\n",
        "\n"
      ],
      "metadata": {
        "id": "2xaqQ2wOijlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02bafb7-fce1-443b-a171-f0fd5fb68267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processor = VideoProcessor(\"/content/best.pt\")\n",
        "video_procesado = processor.process_video(\n",
        "    input_path=r\"/content/Sample8.mp4\",\n",
        "    output_path=r\"/content/SampleFT8.mp4\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohg3v5q7kFvg",
        "outputId": "f8f69d72-b24b-4ac1-b93b-da45543b4bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 536.2ms\n",
            "Speed: 4.5ms preprocess, 536.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 478.9ms\n",
            "Speed: 3.6ms preprocess, 478.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 496.3ms\n",
            "Speed: 3.9ms preprocess, 496.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 490.5ms\n",
            "Speed: 3.2ms preprocess, 490.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 498.3ms\n",
            "Speed: 3.2ms preprocess, 498.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 479.5ms\n",
            "Speed: 3.3ms preprocess, 479.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 502.9ms\n",
            "Speed: 3.2ms preprocess, 502.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 487.4ms\n",
            "Speed: 3.3ms preprocess, 487.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 493.2ms\n",
            "Speed: 4.0ms preprocess, 493.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 484.1ms\n",
            "Speed: 3.4ms preprocess, 484.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 481.8ms\n",
            "Speed: 3.5ms preprocess, 481.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 486.9ms\n",
            "Speed: 3.6ms preprocess, 486.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 469.0ms\n",
            "Speed: 3.6ms preprocess, 469.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 506.9ms\n",
            "Speed: 4.9ms preprocess, 506.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 485.1ms\n",
            "Speed: 3.5ms preprocess, 485.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 487.6ms\n",
            "Speed: 3.3ms preprocess, 487.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 655.4ms\n",
            "Speed: 3.5ms preprocess, 655.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 743.0ms\n",
            "Speed: 5.0ms preprocess, 743.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 753.1ms\n",
            "Speed: 3.5ms preprocess, 753.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 715.9ms\n",
            "Speed: 3.6ms preprocess, 715.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 457.0ms\n",
            "Speed: 3.6ms preprocess, 457.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 511.6ms\n",
            "Speed: 3.8ms preprocess, 511.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 478.6ms\n",
            "Speed: 3.5ms preprocess, 478.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 502.5ms\n",
            "Speed: 4.6ms preprocess, 502.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 497.8ms\n",
            "Speed: 3.7ms preprocess, 497.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 507.2ms\n",
            "Speed: 3.9ms preprocess, 507.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 511.4ms\n",
            "Speed: 3.8ms preprocess, 511.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 506.3ms\n",
            "Speed: 3.5ms preprocess, 506.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 482.7ms\n",
            "Speed: 3.6ms preprocess, 482.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 500.1ms\n",
            "Speed: 4.0ms preprocess, 500.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 488.9ms\n",
            "Speed: 3.8ms preprocess, 488.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 505.7ms\n",
            "Speed: 3.5ms preprocess, 505.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 498.4ms\n",
            "Speed: 3.3ms preprocess, 498.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 500.5ms\n",
            "Speed: 3.4ms preprocess, 500.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 481.2ms\n",
            "Speed: 3.2ms preprocess, 481.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 505.4ms\n",
            "Speed: 3.6ms preprocess, 505.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 goal_post, 476.1ms\n",
            "Speed: 3.5ms preprocess, 476.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 goal_post, 505.8ms\n",
            "Speed: 3.5ms preprocess, 505.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 goal_post, 480.8ms\n",
            "Speed: 3.5ms preprocess, 480.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 goal_post, 678.0ms\n",
            "Speed: 3.5ms preprocess, 678.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 goal_post, 792.4ms\n",
            "Speed: 3.4ms preprocess, 792.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 goal_post, 759.4ms\n",
            "Speed: 3.4ms preprocess, 759.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 goal_post, 709.7ms\n",
            "Speed: 3.7ms preprocess, 709.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 goal_post, 499.7ms\n",
            "Speed: 3.3ms preprocess, 499.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 476.6ms\n",
            "Speed: 3.3ms preprocess, 476.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 476.6ms\n",
            "Speed: 4.0ms preprocess, 476.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 493.0ms\n",
            "Speed: 3.6ms preprocess, 493.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 483.3ms\n",
            "Speed: 3.5ms preprocess, 483.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 489.2ms\n",
            "Speed: 3.6ms preprocess, 489.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 506.2ms\n",
            "Speed: 3.7ms preprocess, 506.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 508.6ms\n",
            "Speed: 3.5ms preprocess, 508.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 490.5ms\n",
            "Speed: 3.8ms preprocess, 490.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 512.2ms\n",
            "Speed: 3.7ms preprocess, 512.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 481.8ms\n",
            "Speed: 3.5ms preprocess, 481.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 520.8ms\n",
            "Speed: 3.7ms preprocess, 520.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 496.1ms\n",
            "Speed: 2.8ms preprocess, 496.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 508.8ms\n",
            "Speed: 3.7ms preprocess, 508.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 533.0ms\n",
            "Speed: 3.0ms preprocess, 533.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 500.2ms\n",
            "Speed: 3.3ms preprocess, 500.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 523.1ms\n",
            "Speed: 3.3ms preprocess, 523.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 498.1ms\n",
            "Speed: 4.0ms preprocess, 498.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 517.1ms\n",
            "Speed: 3.9ms preprocess, 517.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 766.9ms\n",
            "Speed: 3.3ms preprocess, 766.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 779.4ms\n",
            "Speed: 3.6ms preprocess, 779.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 770.7ms\n",
            "Speed: 3.2ms preprocess, 770.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ball, 1 goal_post, 630.4ms\n",
            "Speed: 3.7ms preprocess, 630.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "04rAFKarYdmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tracking balón**"
      ],
      "metadata": {
        "id": "geAdL0n-YwgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "class VideoProcessor:\n",
        "    def __init__(self, model_path):\n",
        "        # Carga del modelo personalizado\n",
        "        self.model = YOLO(model_path)\n",
        "        # Mapeo de clases: ajusta según corresponda a tu entrenamiento\n",
        "        self.class_names = {0: \"balon\", 1: \"arco\"}\n",
        "        # Mapeo de colores en formato BGR\n",
        "        self.colors = {\n",
        "            \"balon\": (0, 0, 255),      # rojo\n",
        "            \"arco\": (255, 0, 0)        # azul\n",
        "        }\n",
        "        # Tracker CSRT de OpenCV (inicialmente None)\n",
        "        self.tracker = None\n",
        "        self.last_ball_bbox = None  # [x, y, w, h] en coordenadas de frame original\n",
        "\n",
        "    def process_video(self, input_path, output_path):\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise IOError(f\"No se pudo abrir el video: {input_path}\")\n",
        "\n",
        "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            original_frame = frame.copy()\n",
        "\n",
        "            # Preprocesamiento para YOLO\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            resized = cv2.resize(gray, (640, 640))\n",
        "            input_frame = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            # Detección con YOLO\n",
        "            results = self.model(input_frame)\n",
        "            boxes = results[0].boxes\n",
        "            xyxy = boxes.xyxy.cpu().numpy()\n",
        "            confs = boxes.conf.cpu().numpy()\n",
        "            classes = boxes.cls.cpu().numpy()\n",
        "\n",
        "            # Escala de coordenadas\n",
        "            scale_x = width / 640\n",
        "            scale_y = height / 640\n",
        "\n",
        "            # Filtramos solo la pelota (clase 0) y tomamos la de mayor confianza\n",
        "            ball_indices = [i for i, cls in enumerate(classes) if int(cls) == 0]\n",
        "            if ball_indices:\n",
        "                # Hay al menos una detección de pelota\n",
        "                # Escogemos la de mayor confianza\n",
        "                best_i = max(ball_indices, key=lambda i: confs[i])\n",
        "                x1, y1, x2, y2 = xyxy[best_i]\n",
        "                # Convertir a coordenadas originales\n",
        "                x1, y1 = int(x1 * scale_x), int(y1 * scale_y)\n",
        "                x2, y2 = int(x2 * scale_x), int(y2 * scale_y)\n",
        "                w, h = x2 - x1, y2 - y1\n",
        "\n",
        "                # Dibujar YOLO\n",
        "                cv2.rectangle(original_frame, (x1, y1), (x2, y2), self.colors[\"balon\"], 2)\n",
        "                cv2.putText(original_frame, f\"balon {confs[best_i]:.2f}\", (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"balon\"], 2)\n",
        "\n",
        "                # (Re)inicializar tracker CSRT con la caja detectada\n",
        "                self.tracker = cv2.TrackerCSRT_create()\n",
        "                self.last_ball_bbox = (x1, y1, w, h)\n",
        "                self.tracker.init(original_frame, self.last_ball_bbox)\n",
        "\n",
        "            else:\n",
        "                # YOLO no detectó la pelota: usar tracker como respaldo\n",
        "                if self.tracker is not None:\n",
        "                    ok, bbox = self.tracker.update(original_frame)\n",
        "                    if ok:\n",
        "                        # Tracker encontró la pelota\n",
        "                        x, y, w, h = [int(v) for v in bbox]\n",
        "                        cv2.rectangle(original_frame, (x, y), (x + w, y + h), self.colors[\"balon\"], 2)\n",
        "                        cv2.putText(original_frame, \"balon (track)\", (x, y - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"balon\"], 2)\n",
        "                        self.last_ball_bbox = (x, y, w, h)\n",
        "                    else:\n",
        "                        # Tracker falló: descartarlo hasta próxima detección\n",
        "                        self.tracker = None\n",
        "                        self.last_ball_bbox = None\n",
        "\n",
        "            # Además dibujamos detecciones de \"arco\" si las hay\n",
        "            for (x1, y1, x2, y2), conf, cls in zip(xyxy, confs, classes):\n",
        "                if int(cls) == 1:  # clase \"arco\"\n",
        "                    x1, y1 = int(x1 * scale_x), int(y1 * scale_y)\n",
        "                    x2, y2 = int(x2 * scale_x), int(y2 * scale_y)\n",
        "                    cv2.rectangle(original_frame, (x1, y1), (x2, y2), self.colors[\"arco\"], 2)\n",
        "                    cv2.putText(original_frame, f\"arco {conf:.2f}\", (x1, y1 - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"arco\"], 2)\n",
        "\n",
        "            out.write(original_frame)\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        return output_path\n"
      ],
      "metadata": {
        "id": "wejQVI6JYcPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = VideoProcessor(\"/content/best.pt\")\n",
        "video_procesado = processor.process_video(\n",
        "    input_path=r\"/content/Sample5.mp4\",\n",
        "    output_path=r\"/content/Sample5seguimiente.mp4\"\n",
        ")"
      ],
      "metadata": {
        "id": "bNNE2z1zY47N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_xwOMAuXihnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cuadricula Cancha + detección puntaje**"
      ],
      "metadata": {
        "id": "wv6qrxmAgt8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "class VideoProcessor:\n",
        "    def __init__(self, model_path):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.class_names = {0: \"balon\", 1: \"arco\"}\n",
        "        self.colors = {\n",
        "            \"balon\": (0, 0, 255),  # rojo\n",
        "            \"arco\": (255, 0, 0)    # azul\n",
        "        }\n",
        "        self.tracker = None\n",
        "        self.last_ball_bbox = None\n",
        "        self.puntaje_asignado = None  # <- nuevo\n",
        "\n",
        "    def process_video(self, input_path, output_path):\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise IOError(f\"No se pudo abrir el video: {input_path}\")\n",
        "\n",
        "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            original_frame = frame.copy()\n",
        "\n",
        "            # Preprocesamiento para YOLO\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            resized = cv2.resize(gray, (640, 640))\n",
        "            input_frame = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            results = self.model(input_frame)\n",
        "            boxes = results[0].boxes\n",
        "            xyxy = boxes.xyxy.cpu().numpy()\n",
        "            confs = boxes.conf.cpu().numpy()\n",
        "            classes = boxes.cls.cpu().numpy()\n",
        "\n",
        "            scale_x = width / 640\n",
        "            scale_y = height / 640\n",
        "\n",
        "            ball_indices = [i for i, cls in enumerate(classes) if int(cls) == 0]\n",
        "            if ball_indices:\n",
        "                best_i = max(ball_indices, key=lambda i: confs[i])\n",
        "                x1, y1, x2, y2 = xyxy[best_i]\n",
        "                x1, y1 = int(x1 * scale_x), int(y1 * scale_y)\n",
        "                x2, y2 = int(x2 * scale_x), int(y2 * scale_y)\n",
        "                w, h = x2 - x1, y2 - y1\n",
        "\n",
        "                cv2.rectangle(original_frame, (x1, y1), (x2, y2), self.colors[\"balon\"], 2)\n",
        "                cv2.putText(original_frame, f\"balon {confs[best_i]:.2f}\", (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"balon\"], 2)\n",
        "\n",
        "                self.tracker = cv2.TrackerCSRT_create()\n",
        "                self.last_ball_bbox = (x1, y1, w, h)\n",
        "                self.tracker.init(original_frame, self.last_ball_bbox)\n",
        "            else:\n",
        "                if self.tracker is not None:\n",
        "                    ok, bbox = self.tracker.update(original_frame)\n",
        "                    if ok:\n",
        "                        x, y, w, h = [int(v) for v in bbox]\n",
        "                        cv2.rectangle(original_frame, (x, y), (x + w, y + h), self.colors[\"balon\"], 2)\n",
        "                        cv2.putText(original_frame, \"balon (track)\", (x, y - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"balon\"], 2)\n",
        "                        self.last_ball_bbox = (x, y, w, h)\n",
        "                    else:\n",
        "                        self.tracker = None\n",
        "                        self.last_ball_bbox = None\n",
        "\n",
        "            for (x1, y1, x2, y2), conf, cls in zip(xyxy, confs, classes):\n",
        "                if int(cls) == 1:  # clase \"arco\"\n",
        "                    x1, y1 = int(x1 * scale_x), int(y1 * scale_y)\n",
        "                    x2, y2 = int(x2 * scale_x), int(y2 * scale_y)\n",
        "                    cv2.rectangle(original_frame, (x1, y1), (x2, y2), self.colors[\"arco\"], 2)\n",
        "                    cv2.putText(original_frame, f\"arco {conf:.2f}\", (x1, y1 - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"arco\"], 2)\n",
        "\n",
        "                    # Dibujar cuadrícula\n",
        "                    cell_w = (x2 - x1) // 3\n",
        "                    cell_h = (y2 - y1) // 3\n",
        "                    puntajes = [[5, 2, 5],\n",
        "                                [3, 1, 3],\n",
        "                                [5, 1, 5]]\n",
        "\n",
        "                    for i in range(3):\n",
        "                        for j in range(3):\n",
        "                            cx1 = x1 + j * cell_w\n",
        "                            cy1 = y1 + i * cell_h\n",
        "                            cx2 = cx1 + cell_w\n",
        "                            cy2 = cy1 + cell_h\n",
        "                            cv2.rectangle(original_frame, (cx1, cy1), (cx2, cy2), (0, 255, 0), 1)\n",
        "                            cv2.putText(original_frame, str(puntajes[i][j]), (cx1 + 5, cy1 + 20),\n",
        "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "                    # Determinar puntaje si entra el balón\n",
        "                    if self.last_ball_bbox is not None and self.puntaje_asignado is None:\n",
        "                        bx, by, bw, bh = self.last_ball_bbox\n",
        "                        ball_cx = bx + bw // 2\n",
        "                        ball_cy = by + bh // 2\n",
        "\n",
        "                        if x1 <= ball_cx <= x2 and y1 <= ball_cy <= y2:\n",
        "                            col = (ball_cx - x1) // cell_w\n",
        "                            row = (ball_cy - y1) // cell_h\n",
        "                            col = int(min(max(col, 0), 2))\n",
        "                            row = int(min(max(row, 0), 2))\n",
        "                            self.puntaje_asignado = puntajes[row][col]\n",
        "\n",
        "                            cv2.putText(original_frame, f\"PUNTAJE: {self.puntaje_asignado}\", (50, 50),\n",
        "                                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
        "\n",
        "            out.write(original_frame)\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        if self.puntaje_asignado is not None:\n",
        "            print(f\"Puntaje asignado: {self.puntaje_asignado}\")\n",
        "        else:\n",
        "            print(\"No se detectó un gol en el video.\")\n",
        "\n",
        "        return output_path\n"
      ],
      "metadata": {
        "id": "cyzwqyNOckc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "class VideoProcessor:\n",
        "    def __init__(self, model_path):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.class_names = {0: \"balon\", 1: \"arco\"}\n",
        "        self.colors = {\n",
        "            \"balon\": (0, 0, 255),  # rojo\n",
        "            \"arco\": (255, 0, 0)    # azul\n",
        "        }\n",
        "\n",
        "    def process_video(self, input_path, output_path):\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise IOError(f\"No se pudo abrir el video: {input_path}\")\n",
        "\n",
        "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        tracker = None\n",
        "        last_ball_bbox = None\n",
        "        last_arco_bbox = None\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            original_frame = frame.copy()\n",
        "\n",
        "            # Preprocesamiento para YOLO\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            resized = cv2.resize(gray, (640, 640))\n",
        "            input_frame = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "            results = self.model(input_frame)\n",
        "            boxes = results[0].boxes\n",
        "            xyxy = boxes.xyxy.cpu().numpy()\n",
        "            confs = boxes.conf.cpu().numpy()\n",
        "            classes = boxes.cls.cpu().numpy()\n",
        "\n",
        "            scale_x = width / 640\n",
        "            scale_y = height / 640\n",
        "\n",
        "            # 1) Detectar balón (mejor confianza)\n",
        "            ball_indices = [i for i, cls in enumerate(classes) if int(cls) == 0]\n",
        "            if ball_indices:\n",
        "                best_i = max(ball_indices, key=lambda i: confs[i])\n",
        "                x1, y1, x2, y2 = xyxy[best_i]\n",
        "                x1, y1 = int(x1 * scale_x), int(y1 * scale_y)\n",
        "                x2, y2 = int(x2 * scale_x), int(y2 * scale_y)\n",
        "                w, h = x2 - x1, y2 - y1\n",
        "\n",
        "                cv2.rectangle(original_frame, (x1, y1), (x2, y2), self.colors[\"balon\"], 2)\n",
        "                cv2.putText(original_frame, f\"balon {confs[best_i]:.2f}\", (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"balon\"], 2)\n",
        "\n",
        "                # reiniciar tracker\n",
        "                tracker = cv2.TrackerCSRT_create()\n",
        "                tracker.init(original_frame, (x1, y1, w, h))\n",
        "                last_ball_bbox = (x1, y1, w, h)\n",
        "            else:\n",
        "                # tracking si no detecta\n",
        "                if tracker is not None:\n",
        "                    ok, bbox = tracker.update(original_frame)\n",
        "                    if ok:\n",
        "                        x, y, w, h = [int(v) for v in bbox]\n",
        "                        cv2.rectangle(original_frame, (x, y), (x + w, y + h), self.colors[\"balon\"], 2)\n",
        "                        cv2.putText(original_frame, \"balon (track)\", (x, y - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"balon\"], 2)\n",
        "                        last_ball_bbox = (x, y, w, h)\n",
        "                    else:\n",
        "                        tracker = None\n",
        "\n",
        "            # 2) Detectar arco (podría haber múltiples, tomamos el de mayor confianza)\n",
        "            arco_indices = [i for i, cls in enumerate(classes) if int(cls) == 1]\n",
        "            if arco_indices:\n",
        "                best_j = max(arco_indices, key=lambda i: confs[i])\n",
        "                ax1, ay1, ax2, ay2 = xyxy[best_j]\n",
        "                ax1, ay1 = int(ax1 * scale_x), int(ay1 * scale_y)\n",
        "                ax2, ay2 = int(ax2 * scale_x), int(ay2 * scale_y)\n",
        "\n",
        "                cv2.rectangle(original_frame, (ax1, ay1), (ax2, ay2), self.colors[\"arco\"], 2)\n",
        "                cv2.putText(original_frame, f\"arco {confs[best_j]:.2f}\", (ax1, ay1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, self.colors[\"arco\"], 2)\n",
        "\n",
        "                last_arco_bbox = (ax1, ay1, ax2, ay2)\n",
        "\n",
        "                # dibujar cuadricula (para visual)\n",
        "                cell_w = (ax2 - ax1) // 3\n",
        "                cell_h = (ay2 - ay1) // 3\n",
        "                puntajes = [[5, 2, 5],\n",
        "                            [3, 1, 3],\n",
        "                            [5, 1, 5]]\n",
        "                for i in range(3):\n",
        "                    for j in range(3):\n",
        "                        cx1 = ax1 + j * cell_w\n",
        "                        cy1 = ay1 + i * cell_h\n",
        "                        cx2 = cx1 + cell_w\n",
        "                        cy2 = cy1 + cell_h\n",
        "                        cv2.rectangle(original_frame, (cx1, cy1), (cx2, cy2), (0, 255, 0), 1)\n",
        "                        cv2.putText(original_frame, str(puntajes[i][j]), (cx1 + 5, cy1 + 20),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "            out.write(original_frame)\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        # 3) Al final, calcular puntaje si hubo balón y arco\n",
        "        puntaje_asignado = None\n",
        "        if last_ball_bbox and last_arco_bbox:\n",
        "            bx, by, bw, bh = last_ball_bbox\n",
        "            ball_cx = bx + bw // 2\n",
        "            ball_cy = by + bh // 2\n",
        "\n",
        "            ax1, ay1, ax2, ay2 = last_arco_bbox\n",
        "            if ax1 <= ball_cx <= ax2 and ay1 <= ball_cy <= ay2:\n",
        "                cell_w = (ax2 - ax1) // 3\n",
        "                cell_h = (ay2 - ay1) // 3\n",
        "                puntajes = [[5, 2, 5],\n",
        "                            [3, 1, 3],\n",
        "                            [5, 1, 5]]\n",
        "                col = int(min(max((ball_cx - ax1) // cell_w, 0), 2))\n",
        "                row = int(min(max((ball_cy - ay1) // cell_h, 0), 2))\n",
        "                puntaje_asignado = puntajes[row][col]\n",
        "\n",
        "        if puntaje_asignado is not None:\n",
        "            print(f\"Puntaje asignado: {puntaje_asignado}\")\n",
        "        else:\n",
        "            print(\"No se detectó un gol en el video.\")\n",
        "\n",
        "        return output_path\n"
      ],
      "metadata": {
        "id": "j36G7gjxmqWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = VideoProcessor(\"/content/best.pt\")\n",
        "video_procesado = processor.process_video(\n",
        "    input_path=r\"/content/Sample3-recortado.mp4\",\n",
        "    output_path=r\"/content/Sample3Gol.mp4\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq4bvtD-kfaW",
        "outputId": "5476408f-02b3-4124-f0af-a8f7d6784d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Puntaje asignado: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8R7J4wdMcize"
      }
    }
  ]
}